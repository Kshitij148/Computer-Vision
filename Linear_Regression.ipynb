{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In linear regression model,each target variable is estimated to be a weighted \n",
    "#sum of the input variables,offset by some constant known as bias\n",
    "\n",
    "#yield=weight1* parameter1+weight1*parameter2+weightn*parametern + b(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input(temp,rainfall,humidity)\n",
    "\n",
    "inputs=np.array([[73,67,43],\n",
    "                  [91,88,64],\n",
    "                  [87,134,58],\n",
    "                  [102,43,37],\n",
    "                  [69,96,70]],dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Targets(apples,oranges)\n",
    "\n",
    "targets=np.array([[56,70],\n",
    "                 [81,101],\n",
    "                 [119,133],\n",
    "                 [22,37],\n",
    "                 [103,119]],dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "#convert inputs and targets to tensors\n",
    "inputs=torch.from_numpy(inputs)\n",
    "targets=torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7509,  0.4957, -0.1962],\n",
      "        [ 0.7992,  0.0389,  0.8197]], requires_grad=True)\n",
      "tensor([-1.6893, -0.3677], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#weights and biases\n",
    "w=torch.randn(2,3,requires_grad=True)\n",
    "b=torch.randn(2,requires_grad=True)\n",
    "print(w)\n",
    "print(b)\n",
    "\n",
    "#torch.randn creates a tensors of given dimensions with mean of 0 and standard deviation \n",
    "#of 1 (normal distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() +b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w.t() returns the transpose of the tensor \n",
    "#@ is for matrix multiplication\n",
    "#python makes first column of b repeat n times where n is the number of rows in the result of matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-104.7326,   95.8279],\n",
      "        [-129.9599,  128.2440],\n",
      "        [ -98.9789,  121.9200],\n",
      "        [-166.2278,  113.1523],\n",
      "        [ -88.6516,  115.8910]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Generate predictions\n",
    "preds=model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "#compare with targets\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19735.4785, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff=preds-targets\n",
    "torch.sum(diff*diff)/diff.numel()   #to find mean squared error\n",
    "\n",
    "#torch.sum(tensor_name) it adds all the elements in the tensor\n",
    "#matrix_name.numel() gives the number of elements in the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute Loss function (mean squared error) \n",
    "\n",
    "def mse(t1,t2):\n",
    "    diff=t1-t2\n",
    "    return torch.sum(diff*diff)/diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19735.4785, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss=mse(preds,targets)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute gradients(derivatives)\n",
    "#loss is a quadratic function of weigths and biases\n",
    "#inputs and targets are not changing only the weights and biases are changing\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7509,  0.4957, -0.1962],\n",
      "        [ 0.7992,  0.0389,  0.8197]], requires_grad=True)\n",
      "tensor([[-16463.6367, -17007.0137, -10687.1494],\n",
      "        [  2190.7378,   1123.8601,    962.3153]])\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(w.grad) #returns the derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objective to find set of weights where loss is the lowest\n",
    "#the derivative of loss curve(loss function) represents the slope of loss function with respect to the weights and biases (the rate of change of loss)\n",
    "#move in opposite direction of sign of slope\n",
    "#derivative positive decrease the weights slightly\n",
    "#derivative negative increase the weights slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()   #after use make the grad value back to zero as pytorch dust not replace it will keep on adding to the gradients when backward is called again\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-104.7326,   95.8279],\n",
      "        [-129.9599,  128.2440],\n",
      "        [ -98.9789,  121.9200],\n",
      "        [-166.2278,  113.1523],\n",
      "        [ -88.6516,  115.8910]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#revision repeat of steps\n",
    "#generate predictions\n",
    "preds=model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19735.4785, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#calculate the loss\n",
    "loss=mse(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-16463.6367, -17007.0137, -10687.1494],\n",
      "        [  2190.7378,   1123.8601,    962.3153]])\n",
      "tensor([-193.9101,   23.0070])\n"
     ]
    }
   ],
   "source": [
    "#compute gradients\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust weights and reset gradients  very very important\n",
    "#torch.no_grad to indicate to pytorch that we shouldn't track,calculate or modify gradients while updating the weights and biases\n",
    "#1e-5 this means 1 *10 to the power -5 \n",
    "#subtracting the gradient from the weights decreases the weight but sometimes the gradient values are large so \n",
    "#we subtract the weights by a small portion the gradients\n",
    "#negative gradients will automatically add as negative of negative is positive thereby increasing the value\n",
    "\n",
    "#as\n",
    "#move in opposite direction of sign of slope\n",
    "#derivative positive decrease the weights slightly\n",
    "#derivative negative increase the weights slightly\n",
    "\n",
    "with torch.no_grad():\n",
    "    w-=w.grad*1e-5\n",
    "    b-=b.grad*1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5863,  0.6657, -0.0893],\n",
      "        [ 0.7773,  0.0277,  0.8100]], requires_grad=True)\n",
      "tensor([-1.6874, -0.3679], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13529.6592, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#calculate loss\n",
    "preds=model(inputs)\n",
    "loss=mse(preds,targets)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting everything in a loop\n",
    "#every run of this loop is called epoch in machine learning\n",
    "for i in range(100):\n",
    "    preds=model(inputs)\n",
    "    loss=mse(preds,targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w-=w.grad*1e-5\n",
    "        b-=b.grad*1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(207.7222, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#calculate loss\n",
    "preds=model(inputs)\n",
    "loss=mse(preds,targets)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 54.1546,  75.7929],\n",
       "        [ 77.6295, 104.6361],\n",
       "        [133.9382, 115.1215],\n",
       "        [  4.9585,  69.2762],\n",
       "        [103.0351, 107.1375]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
